[
  {
    "objectID": "blog/project1/hw1_questions (1).html",
    "href": "blog/project1/hw1_questions (1).html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project1/hw1_questions (1).html#introduction",
    "href": "blog/project1/hw1_questions (1).html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project1/hw1_questions (1).html#data",
    "href": "blog/project1/hw1_questions (1).html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\nx =2\nprint(x)\n\n2\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "blog/project1/hw1_questions (1).html#experimental-results",
    "href": "blog/project1/hw1_questions (1).html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "blog/project1/hw1_questions (1).html#simulation-experiment",
    "href": "blog/project1/hw1_questions (1).html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "Multinomial Logit Model\n\n\n\n\n\n\nYour Name\n\n\nMay 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nTimon Ortwein\n\n\nMay 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nTimon Ortwein\n\n\nMay 26, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Timon Ortwein",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "blog/project1/hw1_questions.html",
    "href": "blog/project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment was designed to test whether offering a matching grant would increase charitable donations compared to a standard appeal. The researchers were particularly interested in whether different match ratios (1:1, 2:1, and 3:1) would have different effects on donation rates. This project seeks to replicate their results and explore the effectiveness of matching grants in charitable fundraising."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#introduction",
    "href": "blog/project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment was designed to test whether offering a matching grant would increase charitable donations compared to a standard appeal. The researchers were particularly interested in whether different match ratios (1:1, 2:1, and 3:1) would have different effects on donation rates. This project seeks to replicate their results and explore the effectiveness of matching grants in charitable fundraising."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#data",
    "href": "blog/project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.formula.api as smf\nimport scipy.stats as stats\n\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_palette(\"viridis\")\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\nprint(\"Dataset shape:\", df.shape)\nprint(\"\\nFirst few rows of the dataset:\")\ndf.head()\n\nDataset shape: (50083, 51)\n\nFirst few rows of the dataset:\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\nThe dataset contains information on 50,000 potential donors who received fundraising letters. Each observation represents one recipient, with variables indicating whether they received a treatment (matching grant) or control letter, the match ratio if applicable, and whether they made a donation.\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code"
  },
  {
    "objectID": "blog/project1/hw1_questions.html#experimental-results",
    "href": "blog/project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n# Analyze impact of matching grants on donation probability using multiple statistical approaches\ndonation_rates = df.groupby(\"treatment\")[\"gave\"].mean()\ndonation_rates.index = [\"Control\", \"Treatment\"]\n\nplt.figure(figsize=(10, 6))\nax = donation_rates.plot(kind=\"bar\", color=['blue', 'green'])\nplt.ylabel(\"Proportion Donated\", fontsize=12)\nplt.title(\"Donation Rate by Treatment Group\", fontsize=14)\nplt.ylim(0, 0.04)\n\nfor i, v in enumerate(donation_rates):\n    ax.text(i, v + 0.002, f\"{v:.3f}\", ha='center', fontsize=11)\n\nplt.tight_layout()\nplt.show()\n\ncontrol_gave = df[df[\"treatment\"] == 0][\"gave\"]\ntreat_gave = df[df[\"treatment\"] == 1][\"gave\"]\nt_stat_gave, p_val_gave = stats.ttest_ind(treat_gave, control_gave)\nprint(\"T-test for donation rate:\")\nprint(f\"t-statistic: {t_stat_gave:.4f}\")\nprint(f\"p-value: {p_val_gave:.4f}\")\n\nmodel_gave = smf.ols(\"gave ~ treatment\", data=df).fit()\nprint(\"\\nLinear regression for donation rate:\")\nprint(model_gave.summary().tables[1])\n\nprobit_model = smf.probit(\"gave ~ treatment\", data=df).fit()\nprint(\"\\nProbit regression for donation rate:\")\nprint(probit_model.summary().tables[1])\n\nmfx = probit_model.get_margeff()\nprint(\"\\nMarginal effects:\")\nprint(mfx.summary().tables[0])\n\n\n\n\n\n\n\n\nT-test for donation rate:\nt-statistic: 3.1014\np-value: 0.0019\n\nLinear regression for donation rate:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\nProbit regression for donation rate:\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\nMarginal effects:\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n=====================================\n\n\nThe results show that the treatment group had a higher donation rate compared to the control group. This difference is statistically significant, indicating that offering a matching grant increases the likelihood of receiving a donation.\nFrom a behavioral perspective, this suggests that the presence of a matching grant creates a sense of urgency or leverage that motivates potential donors to give. The matching grant effectively multiplies the impact of their donation, which appears to be a compelling incentive. ### Differences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n# Compare effectiveness of different match ratios (1:1, 2:1, 3:1) on donation rates\ntreat_df = df[df[\"treatment\"] == 1].copy()\n\nfor col in [\"ratio\", \"ratio2\", \"ratio3\"]:\n    treat_df[col] = pd.to_numeric(treat_df[col], errors='coerce').fillna(0).astype(int)\n\ntreat_df[\"ratio1\"] = treat_df[\"ratio\"]\n\nratio_rates = treat_df.groupby([\"ratio1\", \"ratio2\", \"ratio3\"])[\"gave\"].mean()\nprint(\"Donation rates by match ratio:\")\nprint(ratio_rates)\n\ngroup_1_1 = treat_df[treat_df[\"ratio1\"] == 1][\"gave\"]\ngroup_2_1 = treat_df[treat_df[\"ratio2\"] == 1][\"gave\"]\nt_2, p_2 = stats.ttest_ind(group_2_1, group_1_1)\nprint(\"\\n2:1 vs 1:1 match rate:\")\nprint(f\"t-statistic: {t_2:.4f}\")\nprint(f\"p-value: {p_2:.4f}\")\n\ngroup_3_1 = treat_df[treat_df[\"ratio3\"] == 1][\"gave\"]\nt_3, p_3 = stats.ttest_ind(group_3_1, group_1_1)\nprint(\"\\n3:1 vs 1:1 match rate:\")\nprint(f\"t-statistic: {t_3:.4f}\")\nprint(f\"p-value: {p_3:.4f}\")\n\nmodel_ratio = smf.ols(\"gave ~ ratio1 + ratio2 + ratio3\", data=treat_df).fit()\nprint(\"\\nRegression on match ratios:\")\nprint(model_ratio.summary().tables[1])\n\nresponse_1_1 = treat_df[treat_df[\"ratio1\"] == 1][\"gave\"].mean()\nresponse_2_1 = treat_df[treat_df[\"ratio2\"] == 1][\"gave\"].mean()\nresponse_3_1 = treat_df[treat_df[\"ratio3\"] == 1][\"gave\"].mean()\n\ndiff_2v1 = response_2_1 - response_1_1\ndiff_3v2 = response_3_1 - response_2_1\n\nprint(\"\\nResponse rate differences:\")\nprint(f\"2:1 vs 1:1: {diff_2v1:.4f}\")\nprint(f\"3:1 vs 2:1: {diff_3v2:.4f}\")\n\nratio_data = pd.DataFrame({\n    'Match Ratio': ['1:1', '2:1', '3:1'],\n    'Donation Rate': [response_1_1, response_2_1, response_3_1]\n})\n\nplt.figure(figsize=(10, 6))\nax = sns.barplot(x='Match Ratio', y='Donation Rate', data=ratio_data, palette='viridis')\nplt.title('Donation Rate by Match Ratio', fontsize=14)\nplt.ylabel('Proportion Donated', fontsize=12)\n\nfor i, v in enumerate(ratio_data['Donation Rate']):\n    ax.text(i, v + 0.001, f\"{v:.3f}\", ha='center', fontsize=11)\n\nplt.tight_layout()\nplt.show()\n\nDonation rates by match ratio:\nratio1  ratio2  ratio3\n1       0       0         0.020749\n2       1       0         0.022633\n3       0       1         0.022733\nName: gave, dtype: float64\n\n2:1 vs 1:1 match rate:\nt-statistic: 0.9650\np-value: 0.3345\n\n3:1 vs 1:1 match rate:\nt-statistic: 1.0150\np-value: 0.3101\n\nRegression on match ratios:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept    3.03e+09   1.66e+10      0.183      0.855   -2.95e+10    3.55e+10\nratio1      -3.03e+09   1.66e+10     -0.183      0.855   -3.55e+10    2.95e+10\nratio2       3.03e+09   1.66e+10      0.183      0.855   -2.95e+10    3.55e+10\nratio3       6.06e+09   3.31e+10      0.183      0.855   -5.89e+10     7.1e+10\n==============================================================================\n\nResponse rate differences:\n2:1 vs 1:1: 0.0019\n3:1 vs 2:1: 0.0001\n\n\nC:\\Users\\timon\\AppData\\Local\\Temp\\ipykernel_16356\\474621105.py:47: FutureWarning:\n\n\n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n\n\n\n\n\n\n\n\n\n\nThe results show that there is no statistically significant difference in donation rates between the different match ratios (1:1, 2:1, and 3:1). This is consistent with what Karlan and List suggest in their paper.\nFrom a behavioral perspective, this is an interesting finding. It suggests that while the presence of a match offer itself increases giving, the size of the match offer does not have a significant additional effect. This highlights that what matters most is the perception of support or urgency created by the match, not necessarily the financial efficiency of the match.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# Analyzing the impact of matching grants on donation amounts and visualize distributions\namount_control = df[df[\"treatment\"] == 0][\"amount\"]\namount_treatment = df[df[\"treatment\"] == 1][\"amount\"]\nt_stat_amt, p_val_amt = stats.ttest_ind(amount_treatment, amount_control)\n\nprint(\"T-test on donation amount:\")\nprint(f\"t-statistic: {t_stat_amt:.4f}\")\nprint(f\"p-value: {p_val_amt:.4f}\")\n\nmodel_amt = smf.ols(\"amount ~ treatment\", data=df).fit()\nprint(\"\\nRegression on donation amount:\")\nprint(model_amt.summary().tables[1])\n\ndf_gave = df[df[\"gave\"] == 1].copy()\n\nmodel_cond = smf.ols(\"amount ~ treatment\", data=df_gave).fit()\nprint(\"\\nRegression on donation amount (only for donors):\")\nprint(model_cond.summary().tables[1])\n\nmean_treat = df_gave[df_gave[\"treatment\"] == 1][\"amount\"].mean()\nmean_control = df_gave[df_gave[\"treatment\"] == 0][\"amount\"].mean()\n\nprint(f\"\\nMean donation amount (treatment): ${mean_treat:.2f}\")\nprint(f\"Mean donation amount (control): ${mean_control:.2f}\")\n\nfig, axs = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n\ntreat_donors = df_gave[df_gave[\"treatment\"] == 1][\"amount\"]\naxs[0].hist(treat_donors, bins=30, color='blue', edgecolor='black', alpha=0.7)\naxs[0].axvline(mean_treat, color='red', linestyle='dashed', linewidth=2)\naxs[0].set_title(\"Treatment Group\", fontsize=14)\naxs[0].set_xlabel(\"Donation Amount ($)\", fontsize=12)\naxs[0].set_ylabel(\"Frequency\", fontsize=12)\n\ncontrol_donors = df_gave[df_gave[\"treatment\"] == 0][\"amount\"]\naxs[1].hist(control_donors, bins=30, color='green', edgecolor='black', alpha=0.7)\naxs[1].axvline(mean_control, color='red', linestyle='dashed', linewidth=2)\naxs[1].set_title(\"Control Group\", fontsize=14)\naxs[1].set_xlabel(\"Donation Amount ($)\", fontsize=12)\n\nplt.suptitle(\"Distribution of Donation Amounts (Donors Only)\", fontsize=16, y=1.05)\nplt.tight_layout()\nplt.show()\n\nT-test on donation amount:\nt-statistic: 1.8605\np-value: 0.0628\n\nRegression on donation amount:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\n\nRegression on donation amount (only for donors):\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\n\nMean donation amount (treatment): $43.87\nMean donation amount (control): $45.54\n\n\n\n\n\n\n\n\n\nThe analysis of donation amounts reveals that the treatment group has a lower average donation amount compared to the control group. When considering all potential donors (including non-donors, same as only looking at donors), the treatment effect is negative but not statistically significant.\nThis indicates that the matching grant primarily works by motivating more people to donate rather than by encouraging substantially larger donations from those who would have given anyway."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#simulation-experiment",
    "href": "blog/project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nTo better understand the statistical properties of our results, I’ll conduct a simulation experiment to demonstrate the Law of Large Numbers and the Central Limit Theorem.\n\nLaw of Large Numbers\nThe Law of Large Numbers states that as the sample size increases, the sample mean will converge to the population mean. I’ll simulate this using the true probabilities from our data.\n\n# Simulate Law of Large Numbers to demonstrate convergence of sample means to true difference\nnp.random.seed(42)\n\nn = 10000\np_treat = 0.022\np_control = 0.018\ntrue_diff = p_treat - p_control\n\ntreatment = np.random.binomial(1, p_treat, n)\ncontrol = np.random.binomial(1, p_control, n)\ndiffs = treatment - control\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n + 1)\n\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg, label=\"Cumulative Avg. Difference\", color=\"steelblue\", linewidth=2)\nplt.axhline((-true_diff), color='red', linestyle='--', linewidth=2, label=f\"True Difference ({true_diff:.3f})\")\n\nplt.title(\"Law of Large Numbers Simulation\", fontsize=16, weight='bold')\nplt.xscale('log')\nplt.xlabel(\"Number of Observations\", fontsize=13)\nplt.ylabel(\"Cumulative Average Difference\", fontsize=13)\nplt.grid(True, linestyle=':', alpha=0.7)\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis simulation demonstrates the Law of Large Numbers using our observed donation rates (treatment: 2.2%, control: 1.8%). The cumulative average difference between treatment and control groups converges to the true difference of 0.4 percentage points as the sample size increases. The convergence is particularly rapid in the early observations (note the logarithmic scale), with diminishing improvements as the sample size grows very large.\n\n\nCentral Limit Theorem\nThe Central Limit Theorem states that the distribution of sample means will approach a normal distribution as the sample size increases, regardless of the shape of the population distribution.\n\n# Demonstrate Central Limit Theorem using different sample sizes to show convergence to normal distribution\nn_sim = 1000\nsample_sizes = [50, 200, 500, 1000]\n\nfig, axs = plt.subplots(2, 2, figsize=(14, 10))\naxs = axs.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diff_means = []\n    \n    for _ in range(n_sim):\n        control_sample = np.random.binomial(1, p_control, n)\n        treat_sample = np.random.binomial(1, p_treat, n)\n        diff = treat_sample.mean() - control_sample.mean()\n        diff_means.append(diff)\n\n    axs[i].hist(diff_means, bins=30, color='#3498db', edgecolor='black', alpha=0.7)\n    axs[i].axvline(0, color='red', linestyle='--', linewidth=2)\n    axs[i].set_title(f\"Sample Size: {n}\", fontsize=14)\n    axs[i].set_xlabel(\"Mean Difference (Treatment - Control)\")\n    axs[i].set_ylabel(\"Frequency\")\n\nplt.suptitle(\"Central Limit Theorem Simulation: Distribution of Mean Differences\", \n             fontsize=16, weight='bold')\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()\n\n\n\n\n\n\n\n\nThis simulation demonstrates the Central Limit Theorem. As the sample size increases from 50 to 1000, the distribution of mean differences becomes increasingly normal. This is why we can use t-tests and regression analysis to make statistical inferences, even when the underlying data (donations) is not normally distributed.\nFor the smallest sample size (50), the distribution is still somewhat skewed. However, as the sample size increases to 200, 500, and 1000, the distribution becomes more symmetric and bell-shaped, approaching a normal distribution.\nThis is particularly important for our analysis because it justifies our use of parametric statistical tests, even though charitable donations are typically right-skewed (most people give small amounts, with a few giving very large amounts)."
  },
  {
    "objectID": "blog/project2/hw1_questions.html",
    "href": "blog/project2/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project2/hw1_questions.html#introduction",
    "href": "blog/project2/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project2/hw1_questions.html#data",
    "href": "blog/project2/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "blog/project2/hw1_questions.html#experimental-results",
    "href": "blog/project2/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "blog/project2/hw1_questions.html#simulation-experiment",
    "href": "blog/project2/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”\n\nimport pandas as pd\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\ndf.info()\ndf.head()\nprint(df.columns)\n\n\n## Balance Test\nprint(\"Balance Test\")\n\n# Mean donation rates and amounts by treatment group\ndf.groupby(\"treatment\")[[\"gave\", \"amount\"]].mean()\n\nimport statsmodels.formula.api as smf\n\n# Linear probability model\nmodel_gave = smf.ols(\"gave ~ treatment\", data=df).fit()\nprint(model_gave.summary())\n\n\n# OLS on amount donated\nmodel_amt = smf.ols(\"amount ~ treatment\", data=df).fit()\nprint(model_amt.summary())\nimport scipy.stats as stats\n\n# T-test: compare means of mrm2 by treatment\ncontrol = df[df[\"treatment\"] == 0][\"mrm2\"]\ntreat = df[df[\"treatment\"] == 1][\"mrm2\"]\nt_stat, p_val = stats.ttest_ind(control, treat)\nprint(\"T-test result:\")\nprint(\"t-statistic:\", t_stat)\nprint(\"p-value:\", p_val)\n\n# Linear regression: mrm2 ~ treatment\nmodel = smf.ols(\"mrm2 ~ treatment\", data=df).fit()\nprint(\"\\nLinear regression result:\")\nprint(model.summary())\n\n## Charitable Contribution Made\n\n\nprint(\"Charitable Contribution Made\")\n# q1\n\nimport matplotlib.pyplot as plt\n\n# Calculate proportion of people who donated in each group\ndonation_rates = df.groupby(\"treatment\")[\"gave\"].mean()\ndonation_rates.index = [\"Control\", \"Treatment\"]\n\n# Plot\ndonation_rates.plot(kind=\"bar\")\nplt.ylabel(\"Proportion Donated\")\nplt.title(\"Donation Rate by Treatment Group\")\nplt.ylim(0, 0.04)\nplt.show()\n\n#q2\n\n# T-test\ncontrol = df[df[\"treatment\"] == 0][\"gave\"]\ntreat = df[df[\"treatment\"] == 1][\"gave\"]\nt_stat, p_val = stats.ttest_ind(treat, control)\nprint(\"T-test:\")\nprint(\"t-statistic:\", t_stat)\nprint(\"p-value:\", p_val)\n\n# Linear regression\nmodel = smf.ols(\"gave ~ treatment\", data=df).fit()\nprint(\"\\nLinear Regression:\")\nprint(model.summary())\n\n#q3\n\n# Probit model: gave ~ treatment\nprobit_model = smf.probit(\"gave ~ treatment\", data=df).fit()\nprint(probit_model.summary())\n\nmfx = probit_model.get_margeff()\nprint(mfx.summary())\n\nprint(\"Differences between Match Rates\")\n\ntreat_df = df[df[\"treatment\"] == 1]\n\n# Compare 2:1 vs 1:1\ngroup_1_1 = treat_df[treat_df[\"ratio\"] == 1][\"gave\"]\ngroup_2_1 = treat_df[treat_df[\"ratio2\"] == 1][\"gave\"]\nt_2, p_2 = stats.ttest_ind(group_2_1, group_1_1)\nprint(\"2:1 vs 1:1 match rate:\")\nprint(\"t-statistic:\", t_2, \"p-value:\", p_2)\n\n# Compare 3:1 vs 1:1\ngroup_3_1 = treat_df[treat_df[\"ratio3\"] == 1][\"gave\"]\nt_3, p_3 = stats.ttest_ind(group_3_1, group_1_1)\nprint(\"\\n3:1 vs 1:1 match rate:\")\nprint(\"t-statistic:\", t_3, \"p-value:\", p_3)\n\nprint(\"I tested whether increasing the match ratio from 1:1 to 2:1 or 3:1 significantly \\n increased donation rates. The results showed no statistically significant difference in giving behavior \\n between the groups — consistent with what Karlan and List suggest in the paper. \\n This means that while the presence of a match offer itself increases giving, the size of the match offer does not. From a behavioral standpoint, \\n this highlights that what matters most is the perception of support or urgency, not necessarily the financial efficiency of the match.\")\n\n# Q2\n\n\n# Step 1: Filter only treatment group\ntreat_df = df[df[\"treatment\"] == 1].copy()\n\n# Step 2: Convert dummy columns to clean 0/1 integers\nfor col in [\"ratio\", \"ratio2\", \"ratio3\"]:\n    treat_df[col] = pd.to_numeric(treat_df[col], errors='coerce').fillna(0).astype(int)\n\n# Step 3: Create 'ratio1' (to mirror 'ratio2' and 'ratio3')\ntreat_df[\"ratio1\"] = treat_df[\"ratio\"]  # 1:1 match group\n\n# Step 4: Run regression\nmodel = smf.ols(\"gave ~ ratio1 + ratio2 + ratio3\", data=treat_df).fit()\nprint(model.summary())\n\n# Q3\n\n# Direct response rates from the data\nresponse_1_1 = treat_df[treat_df[\"ratio1\"] == 1][\"gave\"].mean()\nresponse_2_1 = treat_df[treat_df[\"ratio2\"] == 1][\"gave\"].mean()\nresponse_3_1 = treat_df[treat_df[\"ratio3\"] == 1][\"gave\"].mean()\n\n# Differences\ndiff_2v1_data = response_2_1 - response_1_1\ndiff_3v2_data = response_3_1 - response_2_1\n\nprint(\"From data:\")\nprint(\"2:1 vs 1:1 response rate difference:\", diff_2v1_data)\nprint(\"3:1 vs 2:1 response rate difference:\", diff_3v2_data)\n\nmodel = smf.ols(\"gave ~ ratio2 + ratio3\", data=treat_df).fit()\nprint(model.summary())\n\n# Extract coefficients and compute differences\nparams = model.params\ndiff_2v1_reg = params[\"ratio2\"]              # 2:1 vs 1:1\ndiff_3v2_reg = params[\"ratio3\"] - params[\"ratio2\"]  # 3:1 vs 2:1\n\nprint(\"\\nFrom regression coefficients:\")\nprint(\"2:1 vs 1:1:\", diff_2v1_reg)\nprint(\"3:1 vs 2:1:\", diff_3v2_reg)\n\nprint(\" \\nSize of Charitable Contribution \\n\")\n\n# Q1\n\n# T-test: compare average donation amount across groups\namount_control = df[df[\"treatment\"] == 0][\"amount\"]\namount_treatment = df[df[\"treatment\"] == 1][\"amount\"]\nt_stat, p_val = stats.ttest_ind(amount_treatment, amount_control)\n\nprint(\"T-test on donation amount:\")\nprint(\"t-statistic:\", t_stat)\nprint(\"p-value:\", p_val)\n\n# Regression: amount ~ treatment\nmodel = smf.ols(\"amount ~ treatment\", data=df).fit()\nprint(\"\\nRegression on donation amount:\")\nprint(model.summary())\n\n# Q2\n\n# Filter to only people who gave (positive amount)\ndf_gave = df[df[\"gave\"] == 1].copy()\n\n# Regression: amount ~ treatment (conditional on giving)\nmodel_cond = smf.ols(\"amount ~ treatment\", data=df_gave).fit()\n\nprint(\"Regression on donation amount (only for donors):\")\nprint(model_cond.summary())\n\n# Q3\n\nimport matplotlib.pyplot as plt\n\n# Filter to people who donated\ndf_gave = df[df[\"gave\"] == 1]\n\n# Split into treatment and control donors\ntreat_donors = df_gave[df_gave[\"treatment\"] == 1][\"amount\"]\ncontrol_donors = df_gave[df_gave[\"treatment\"] == 0][\"amount\"]\n\n# Calculate means\nmean_treat = treat_donors.mean()\nmean_control = control_donors.mean()\n\n# Plot histograms\nfig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# Treatment group\naxs[0].hist(treat_donors, bins=30, color='skyblue', edgecolor='black')\naxs[0].axvline(mean_treat, color='red', linestyle='dashed', linewidth=2)\naxs[0].set_title(\"Treatment Group\")\naxs[0].set_xlabel(\"Donation Amount\")\naxs[0].set_ylabel(\"Frequency\")\naxs[0].legend([\"Mean\", \"Donors\"])\n\n# Control group\naxs[1].hist(control_donors, bins=30, color='lightgreen', edgecolor='black')\naxs[1].axvline(mean_control, color='red', linestyle='dashed', linewidth=2)\naxs[1].set_title(\"Control Group\")\naxs[1].set_xlabel(\"Donation Amount\")\naxs[1].legend([\"Mean\", \"Donors\"])\n\nplt.tight_layout()\nplt.show()\n\n# Law of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Reproducibility\nnp.random.seed(42)\n\n# Parameters\nn = 10000\np_treat = 0.022\np_control = 0.018\ntrue_diff = p_treat - p_control\n\n# Simulate\ntreatment = np.random.binomial(1, p_treat, n)\ncontrol = np.random.binomial(1, p_control, n)\ndiffs = treatment - control\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n + 1)\n\n# Plot\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg, label=\"Cumulative Avg. Difference\", color=\"steelblue\", linewidth=2)\nplt.axhline(true_diff, color='red', linestyle='--', linewidth=2, label=f\"True Difference ({true_diff:.3f})\")\n\n# Style\nplt.title(\"Law of Large Numbers Simulation\", fontsize=16, weight='bold')\nplt.xscale('log')\n\nplt.xlabel(\"Number of Observations\", fontsize=13)\nplt.ylabel(\"Cumulative Average Difference\", fontsize=13)\nplt.xticks(fontsize=11)\nplt.yticks(fontsize=11)\nplt.legend(fontsize=12)\nplt.grid(True, linestyle=':', alpha=0.7)\nplt.tight_layout()\n\n# Show\nplt.show()\n\n# Central Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters\np_control = 0.018\np_treat = 0.022\nn_sim = 1000\nsample_sizes = [50, 200, 500, 1000]\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Initialize figure\nfig, axs = plt.subplots(2, 2, figsize=(14, 10))\naxs = axs.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    # Store average differences for this sample size\n    diff_means = []\n    \n    for _ in range(n_sim):\n        control_sample = np.random.binomial(1, p_control, n)\n        treat_sample = np.random.binomial(1, p_treat, n)\n        diff = treat_sample.mean() - control_sample.mean()\n        diff_means.append(diff)\n\n    # Plot histogram\n    axs[i].hist(diff_means, bins=30, color='lightblue', edgecolor='black')\n    axs[i].axvline(0, color='red', linestyle='--', linewidth=2)\n    axs[i].set_title(f\"Sample Size: {n}\", fontsize=14)\n    axs[i].set_xlabel(\"Mean Difference (Treatment - Control)\")\n    axs[i].set_ylabel(\"Frequency\")\n\nplt.suptitle(\"Central Limit Theorem Simulation: Distribution of Mean Differences\", fontsize=16, weight='bold')\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\nIndex(['treatment', 'control', 'ratio', 'ratio2', 'ratio3', 'size', 'size25',\n       'size50', 'size100', 'sizeno', 'ask', 'askd1', 'askd2', 'askd3', 'ask1',\n       'ask2', 'ask3', 'amount', 'gave', 'amountchange', 'hpa', 'ltmedmra',\n       'freq', 'years', 'year5', 'mrm2', 'dormant', 'female', 'couple',\n       'state50one', 'nonlit', 'cases', 'statecnt', 'stateresponse',\n       'stateresponset', 'stateresponsec', 'stateresponsetminc', 'perbush',\n       'close25', 'red0', 'blue0', 'redcty', 'bluecty', 'pwhite', 'pblack',\n       'page18_39', 'ave_hh_sz', 'median_hhincome', 'powner', 'psch_atlstba',\n       'pop_propurban'],\n      dtype='object')\nBalance Test\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        18:52:09   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        18:52:09   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nT-test result:\nt-statistic: nan\np-value: nan\n\nLinear regression result:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):              0.905\nTime:                        18:52:09   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nCharitable Contribution Made\n\n\n\n\n\n\n\n\n\nT-test:\nt-statistic: 3.101361000543946\np-value: 0.0019274025949016982\n\nLinear Regression:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        18:52:10   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Mon, 21 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        18:52:10   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\nDifferences between Match Rates\n2:1 vs 1:1 match rate:\nt-statistic: 0.96504713432247 p-value: 0.33453168549723933\n\n3:1 vs 1:1 match rate:\nt-statistic: 1.0150255853798622 p-value: 0.31010466370866724\nI tested whether increasing the match ratio from 1:1 to 2:1 or 3:1 significantly \n increased donation rates. The results showed no statistically significant difference in giving behavior \n between the groups — consistent with what Karlan and List suggest in the paper. \n This means that while the presence of a match offer itself increases giving, the size of the match offer does not. From a behavioral standpoint, \n this highlights that what matters most is the perception of support or urgency, not necessarily the financial efficiency of the match.\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.4190\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):              0.739\nTime:                        18:52:10   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33392   BIC:                        -3.333e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept    3.03e+09   1.66e+10      0.183      0.855   -2.95e+10    3.55e+10\nratio1      -3.03e+09   1.66e+10     -0.183      0.855   -3.55e+10    2.95e+10\nratio2       3.03e+09   1.66e+10      0.183      0.855   -2.95e+10    3.55e+10\nratio3       6.06e+09   3.31e+10      0.183      0.855   -5.89e+10     7.1e+10\n==============================================================================\nOmnibus:                    38964.381   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506591.521\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.395   Cond. No.                     1.32e+14\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 1.12e-23. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\nFrom data:\n2:1 vs 1:1 response rate difference: 0.0018842510217149944\n3:1 vs 2:1 response rate difference: 0.00010002398025293902\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):              0.524\nTime:                        18:52:10   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0019      0.002      0.958      0.338      -0.002       0.006\nratio3         0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nFrom regression coefficients:\n2:1 vs 1:1: 0.001884251021714829\n3:1 vs 2:1: 0.0001000239802529453\n \nSize of Charitable Contribution \n\nT-test on donation amount:\nt-statistic: 1.8605020225753781\np-value: 0.06282038947470686\n\nRegression on donation amount:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        18:52:11   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nRegression on donation amount (only for donors):\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):              0.561\nTime:                        18:52:11   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#conclusion",
    "href": "blog/project1/hw1_questions.html#conclusion",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Conclusion",
    "text": "Conclusion\nKey findings from this replication:\n\nMatching grants significantly increase donation rates by 0.4 percentage points (from 1.8% to 2.2%, p &lt; 0.002)\nHigher match ratios (2:1 or 3:1 vs 1:1) do not yield additional benefits (all p-values &gt; 0.85)\nWhile the treatment group shows lower average donations, this difference is not statistically significant\n\nThese results suggest nonprofits can effectively use matching grants without needing to secure higher match ratios."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#balance-tests",
    "href": "blog/project1/hw1_questions.html#balance-tests",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Balance Tests",
    "text": "Balance Tests\nBefore analyzing the treatment effects, it’s important to verify that the randomization was successful. A proper randomization should result in treatment and control groups that are statistically similar in terms of observable characteristics. This is known as a balance test.\n\nMonths since last donation\nGender (female indicator)\nCouple status\n\nT-tests show no significant differences between groups, confirming successful randomization.\n\n# Balance tests comparing treatment and control groups\ncontrol = df[df['treatment'] == 0]\ntreat = df[df['treatment'] == 1]\n\n# T-tests for key variables\nfor var in ['mrm2', 'female', 'couple']:\n    t_stat, p_val = stats.ttest_ind(control[var].dropna(), treat[var].dropna())\n    print(f\"{var}: t-stat = {t_stat:.3f}, p-value = {p_val:.3f}\")\n\nmrm2: t-stat = -0.119, p-value = 0.905\nfemale: t-stat = 1.758, p-value = 0.079\ncouple: t-stat = 0.584, p-value = 0.559"
  },
  {
    "objectID": "blog/project1/hw1_questions.html#balance-test",
    "href": "blog/project1/hw1_questions.html#balance-test",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Balance Test",
    "text": "Balance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n# Perform balance tests comparing treatment and control groups across non key variables\ndef compare_groups(df, var_name):\n    control = df[df['treatment'] == 0][var_name].dropna()\n    treat = df[df['treatment'] == 1][var_name].dropna()\n    \n    t_stat = (treat.mean() - control.mean()) / np.sqrt(\n        (treat.var() / len(treat)) + (control.var() / len(control))\n    )\n    p_val = 2 * (1 - stats.t.cdf(abs(t_stat), df=len(treat) + len(control) - 2))\n    \n    model = smf.ols(f\"{var_name} ~ treatment\", data=df).fit()\n    \n    print(f\"\\nResults for {var_name}:\")\n    print(\"-\" * 50)\n    print(f\"Treatment mean: {treat.mean():.3f}\")\n    print(f\"Control mean: {control.mean():.3f}\")\n    print(f\"\\nT-test results:\")\n    print(f\"t-statistic: {t_stat:.3f}\")\n    print(f\"p-value: {p_val:.3f}\")\n    print(f\"\\nRegression results:\")\n    print(model.summary().tables[1])\n    print(\"\\n\")\n\nvariables = ['mrm2', 'female', 'couple', 'freq']\nfor var in variables:\n    compare_groups(df, var)\n\n\nResults for mrm2:\n--------------------------------------------------\nTreatment mean: 13.012\nControl mean: 12.998\n\nT-test results:\nt-statistic: 0.120\np-value: 0.905\n\nRegression results:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\n\n\n\nResults for female:\n--------------------------------------------------\nTreatment mean: 0.275\nControl mean: 0.283\n\nT-test results:\nt-statistic: -1.754\np-value: 0.080\n\nRegression results:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.2827      0.004     80.688      0.000       0.276       0.290\ntreatment     -0.0075      0.004     -1.758      0.079      -0.016       0.001\n==============================================================================\n\n\n\nResults for couple:\n--------------------------------------------------\nTreatment mean: 0.091\nControl mean: 0.093\n\nT-test results:\nt-statistic: -0.582\np-value: 0.560\n\nRegression results:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0930      0.002     41.124      0.000       0.089       0.097\ntreatment     -0.0016      0.003     -0.584      0.559      -0.007       0.004\n==============================================================================\n\n\n\nResults for freq:\n--------------------------------------------------\nTreatment mean: 8.035\nControl mean: 8.047\n\nT-test results:\nt-statistic: -0.111\np-value: 0.912\n\nRegression results:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      8.0473      0.088     91.231      0.000       7.874       8.220\ntreatment     -0.0120      0.108     -0.111      0.912      -0.224       0.200\n==============================================================================\n\n\n\n\nFollowing Table 1 in Karlan and List (2007), I test several pre-treatment variables to verify the randomization:\n\nMonths since last donation (mrm2)\nGender indicator (female)\nCouple status (couple)\nNumber of prior donations (freq)\n\nFor each variable, I conduct both a t-test and a linear regression. The t-test directly compares means between treatment and control groups, while the regression coefficient on the treatment variable represents the difference in means between groups. As expected, both methods yield identical results for each variable. None of the variables show statistically significant differences between treatment and control groups at the 95% confidence level (all p-values &gt; 0.05). This confirms that the randomization was successful in creating balanced groups. Table 1 in the paper serves this exact purpose - to demonstrate that the randomization created comparable groups, allowing us to attribute any differences in outcomes to the treatment rather than pre-existing differences between groups."
  },
  {
    "objectID": "blog/project2/hw2_questions.html",
    "href": "blog/project2/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\n\nLet’s begin by examining the distribution of patents between Blueprinty customers and non-customers. This will give us our first insight into whether there might be a relationship between using Blueprinty’s software and patent success.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.special import factorial, gammaln\nfrom scipy import optimize\nimport statsmodels.api as sm\n\nblueprinty_df = pd.read_csv('blueprinty.csv')\nprint(blueprinty_df.head())\n\n\n   patents     region   age  iscustomer\n0        0    Midwest  32.5           0\n1        3  Southwest  37.5           0\n2        4  Northwest  27.0           1\n3        3  Northeast  24.5           0\n4        3  Southwest  37.0           0\n\n\n\n\n\n\nCode\n# Plot patent distributions\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.hist(blueprinty_df[blueprinty_df['iscustomer'] == 0]['patents'], bins=20, color='red')\nplt.title('Patents Distribution - Non-Customers')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\n\nplt.subplot(1, 2, 2)\nplt.hist(blueprinty_df[blueprinty_df['iscustomer'] == 1]['patents'], bins=20, color='blue')\nplt.title('Patents Distribution - Customers')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.show()\n\n# Calculate mean patents\nmean_patents = blueprinty_df.groupby('iscustomer')['patents'].mean()\nprint(\"Mean Patents by Customer Status:\")\nprint(f\"Non-Customers (0): {mean_patents[0]:.2f}\")\nprint(f\"Customers (1): {mean_patents[1]:.2f}\")\n\n\n\n\n\n\n\n\n\nMean Patents by Customer Status:\nNon-Customers (0): 3.47\nCustomers (1): 4.13\n\n\nThe histograms reveal right-skewed distributions for both groups, with customers showing higher mean patent counts. This suggests a potential association between software usage and patent success, though confounding factors must be considered.\n\n\n\nNext, we examine whether customer status is related to region or firm age, which could confound our analysis.\n\n\nCode\n# Analyze regional distribution\nplt.figure(figsize=(10, 5))\nregional_dist = pd.crosstab(blueprinty_df['region'], blueprinty_df['iscustomer'], normalize='columns') * 100\nregional_dist.plot(kind='bar')\nplt.title('Regional Distribution by Customer Status')\nplt.xlabel('Region')\nplt.ylabel('Percentage')\nplt.legend(['Non-Customers', 'Customers'])\nplt.show()\n\nprint(\"\\nRegional Distribution (%):\")\nprint(regional_dist)\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nsns.boxplot(data=blueprinty_df[blueprinty_df['iscustomer'] == 0], y='age')\nplt.title('Age Distribution - Non-Customers')\nplt.ylabel('Age (years)')\n\nplt.subplot(1, 2, 2)\nsns.boxplot(data=blueprinty_df[blueprinty_df['iscustomer'] == 1], y='age')\nplt.title('Age Distribution - Customers')\nplt.ylabel('Age (years)')\nplt.show()\n\nprint(\"Mean Age by Customer Status:\")\nprint(blueprinty_df.groupby('iscustomer')['age'].mean())\n\n\n&lt;Figure size 960x480 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\nRegional Distribution (%):\niscustomer          0          1\nregion                          \nMidwest     18.351325   7.692308\nNortheast   26.790972  68.191268\nNorthwest   15.505397   6.029106\nSouth       15.309127   7.276507\nSouthwest   24.043180  10.810811\n\n\n\n\n\n\n\n\n\nMean Age by Customer Status:\niscustomer\n0    26.101570\n1    26.900208\nName: age, dtype: float64\n\n\nLooking at the regional distribution, we can observe notable variations in customer adoption across different regions. The northeast region shows higher proportions of Blueprinty customers than others, suggesting potential geographic clustering. This could be due to various factors such as local marketing efforts or other. The age comparison between customers and non-customers reveals that there is not much variation in age. The boxplots show that Blueprinty’s customer base does not significantly tend to differ in age composition from non-customers. The differences in regional distribution underscores the importance of controlling for this variables in our subsequent analysis. Without accounting for these factors, we might incorrectly attribute differences in patent success rates to Blueprinty’s software when they could be partially explained by this underlying characteristic.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nFor a sample of n independent observations \\(Y_1, ..., Y_n\\) from a Poisson distribution with parameter \\(\\lambda\\), the likelihood function is:\n\\(L(\\lambda|Y) = \\prod_{i=1}^n f(Y_i|\\lambda) = \\prod_{i=1}^n \\frac{e^{-\\lambda}\\lambda^{Y_i}}{Y_i!}\\)\nThis represents the probability of observing our data Y given the parameter \\(\\lambda\\). The product comes from the independence of observations.\n\n\nCode\ndef poisson_loglikelihood(lambda_, Y):\n    Y = np.array(Y)\n    n = len(Y)\n    sum_Y = np.sum(Y)\n    sum_log_factorial = np.sum(np.log(factorial(Y)))\n    return -n * lambda_ + sum_Y * np.log(lambda_) - sum_log_factorial\n\n# Calculate MLE\nY = blueprinty_df['patents'].values\nlambda_values = np.linspace(0.1, 10, 100)\n\nlog_likelihoods = [poisson_loglikelihood(lambda_, Y) for lambda_ in lambda_values]\n\nplt.figure(figsize=(10, 6))\nplt.plot(lambda_values, log_likelihoods)\nplt.xlabel('λ (lambda)')\nplt.ylabel('Log-likelihood')\nplt.title('Log-likelihood Function for Poisson Model')\nplt.grid(True)\nplt.show()\n\nsample_mean = round(np.mean(Y),2)\nprint(\"MLE for lambda: {sample_mean}\")\n\n\n\n\n\n\n\n\n\nMLE for lambda: {sample_mean}\n\n\nThe plot above shows the log-likelihood as a function of \\(\\lambda\\). The maximum occurs at the sample mean, which is the MLE for the Poisson rate parameter.\nWe can also confirm this by direct optimization:\n\n\nCode\ndef neg_poisson_loglikelihood(lambda_, Y):\n    return -poisson_loglikelihood(lambda_, Y)\n\nresult = optimize.minimize(neg_poisson_loglikelihood, x0=np.mean(Y), args=(Y,), method='BFGS')\nprint(f\"MLE of λ from optimization: {result.x[0]:.2f}\")\n\n\nMLE of λ from optimization: 3.68\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nTo account for firm characteristics, we fit a Poisson regression model where the expected number of patents depends on age, age squared, region, and customer status.\n\n\nCode\ndef neg_log_likelihood(beta, Y, X):\n    beta = np.asarray(beta, dtype=np.float64)\n    Y = np.asarray(Y, dtype=np.float64)\n    X = np.asarray(X, dtype=np.float64)\n\n    eta = X @ beta\n    eta = np.clip(eta, -20, 20)\n    lambda_ = np.exp(eta)\n\n    log_likelihood = np.sum(Y * eta - lambda_ - gammaln(Y + 1))\n    return -log_likelihood\n\n\nLet’s estimate the Poisson regression model and analyze the results:\n\n\nCode\nfrom scipy.optimize import minimize\n\nY = blueprinty_df['patents'].astype(float).values\nX = blueprinty_df[['age', 'region', 'iscustomer']].copy()\n\nX['age'] = (X['age'] - X['age'].mean()) / X['age'].std()\nX['age_squared'] = X['age'] ** 2\n\nregion_dummies = pd.get_dummies(X['region'], prefix='region', drop_first=True)\n\nX_final = pd.concat([\n    pd.Series(1.0, index=X.index, name='intercept'),\n    X[['age', 'age_squared', 'iscustomer']],\n    region_dummies], axis=1)\n\nX_np = X_final.to_numpy(dtype=np.float64)\n\ninitial_beta = np.zeros(X_np.shape[1])\nresult = minimize(\n    neg_log_likelihood,\n    x0=initial_beta,\n    args=(Y, X_np),\n    method='L-BFGS-B'\n)\n\nbeta_hat = result.x\nhessian_inv = result.hess_inv\ncov_matrix = hessian_inv.todense()\nstandard_errors = np.sqrt(np.diag(cov_matrix))\n\nsummary_df = pd.DataFrame({\n    'Coefficient': beta_hat,\n    'Std. Error': standard_errors\n}, index=X_final.columns)\n\nsummary_df = summary_df.round(4)\nprint(\"\\nPoisson Regression Results:\")\nprint(summary_df)\n\n\n\nPoisson Regression Results:\n                  Coefficient  Std. Error\nintercept              1.3447      1.1150\nage                   -0.0577      0.8972\nage_squared           -0.1558      0.3603\niscustomer             0.2076      0.6343\nregion_Northeast       0.0291      1.2075\nregion_Northwest      -0.0176      1.3685\nregion_South           0.0565      1.3112\nregion_Southwest       0.0506      0.3889\n\n\n\n\n\nNext we double check our result with the built in GLM function:\n\n\nCode\nimport statsmodels.api as sm\n\ndf = blueprinty_df.copy()\ndf['age'] = (df['age'] - df['age'].mean()) / df['age'].std()\ndf['age_squared'] = df['age'] ** 2\n\nregion_dummies = pd.get_dummies(df['region'], prefix='region', drop_first=True)\n\nmodel_df = pd.concat([\n    df[['patents', 'age', 'age_squared', 'iscustomer']],\n    region_dummies], axis=1)\n\ny = model_df['patents'].astype(float)\nX = sm.add_constant(model_df.drop(columns='patents')).astype(float)\n\npoisson_model = sm.GLM(y, X, family=sm.families.Poisson())\npoisson_results = poisson_model.fit()\n\nprint(poisson_results.summary())\n\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                patents   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Mon, 05 May 2025   Deviance:                       2143.3\nTime:                        23:56:19   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n====================================================================================\n                       coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------------\nconst                1.3447      0.038     35.059      0.000       1.270       1.420\nage                 -0.0577      0.015     -3.843      0.000      -0.087      -0.028\nage_squared         -0.1558      0.014    -11.513      0.000      -0.182      -0.129\niscustomer           0.2076      0.031      6.719      0.000       0.147       0.268\nregion_Northeast     0.0292      0.044      0.669      0.504      -0.056       0.115\nregion_Northwest    -0.0176      0.054     -0.327      0.744      -0.123       0.088\nregion_South         0.0566      0.053      1.074      0.283      -0.047       0.160\nregion_Southwest     0.0506      0.047      1.072      0.284      -0.042       0.143\n====================================================================================\n\n\nThe results from the manual calculation matches those from the built-in GLM function. This agreement provides confidence in the validity of the findings and the reliability of the modeling approach.\n\n\n\nThe Poisson regression results provide meaningful insights into the factors associated with patenting success among firms. Most notably, firms that use Blueprinty’s software are predicted to file more patents than comparable firms that do not use the software. This relationship remains positive even after controlling for other characteristics such as firm age and regional location, suggesting that Blueprinty’s tools may be effectively supporting innovation efforts.\nThe model also reveals a non-linear relationship between age and patent output: patenting tends to increase as firms age, but eventually declines, consistent with the idea that younger firms may be more dynamic and innovative, while older firms could become less agile over time.\nI made this assumption as both age and age squared are negative and statistically significant. This pattern suggests an inverted-U relationship. The patenting activity tends to rise as firms age initially, but eventually declines, indicating that older firms may become less innovative over time.\nFinally, the analysis finds no strong or consistent evidence that region plays a significant role in driving patent activity. Once differences in firm-level factors are accounted for, geographic location does not appear to be a major determinant of patenting success.\n\n\n\n\n\nCode\nX_0 = X.copy()\nX_1 = X.copy()\nX_0['iscustomer'] = 0\nX_1['iscustomer'] = 1\n\ny_pred_0 = poisson_results.predict(X_0)\ny_pred_1 = poisson_results.predict(X_1)\n\navg_effect = (y_pred_1 - y_pred_0).mean()\nprint(round(avg_effect,3))\n\n\n0.793\n\n\nTo assess the practical impact of Blueprinty’s software, we estimated the average treatment effect by comparing predicted patent counts for all firms as if they were customers versus non-customers.\nThe analysis suggests that being a customer of Blueprinty’s software has a positive effect on patent success. Using a Poisson regression model, we estimated that firms using Blueprinty’s software are expected to file approximately 0.793 more patents on average compared to similar firms that do not use the software, holding all other firm characteristics constant.\nThese results support the marketing claim that Blueprinty’s software is linked to greater patenting success. This provides strong evidence that customers of Blueprinty tend to outperform non-customers in terms of patent output, even after accounting for other important firm characteristics."
  },
  {
    "objectID": "blog/project2/hw2_questions.html#blueprinty-case-study",
    "href": "blog/project2/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\n\n\nLet’s begin by examining the distribution of patents between Blueprinty customers and non-customers. This will give us our first insight into whether there might be a relationship between using Blueprinty’s software and patent success.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.special import factorial, gammaln\nfrom scipy import optimize\nimport statsmodels.api as sm\n\nblueprinty_df = pd.read_csv('blueprinty.csv')\nprint(blueprinty_df.head())\n\n\n   patents     region   age  iscustomer\n0        0    Midwest  32.5           0\n1        3  Southwest  37.5           0\n2        4  Northwest  27.0           1\n3        3  Northeast  24.5           0\n4        3  Southwest  37.0           0\n\n\n\n\n\n\nCode\n# Plot patent distributions\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.hist(blueprinty_df[blueprinty_df['iscustomer'] == 0]['patents'], bins=20, color='red')\nplt.title('Patents Distribution - Non-Customers')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\n\nplt.subplot(1, 2, 2)\nplt.hist(blueprinty_df[blueprinty_df['iscustomer'] == 1]['patents'], bins=20, color='blue')\nplt.title('Patents Distribution - Customers')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.show()\n\n# Calculate mean patents\nmean_patents = blueprinty_df.groupby('iscustomer')['patents'].mean()\nprint(\"Mean Patents by Customer Status:\")\nprint(f\"Non-Customers (0): {mean_patents[0]:.2f}\")\nprint(f\"Customers (1): {mean_patents[1]:.2f}\")\n\n\n\n\n\n\n\n\n\nMean Patents by Customer Status:\nNon-Customers (0): 3.47\nCustomers (1): 4.13\n\n\nThe histograms reveal right-skewed distributions for both groups, with customers showing higher mean patent counts. This suggests a potential association between software usage and patent success, though confounding factors must be considered.\n\n\n\nNext, we examine whether customer status is related to region or firm age, which could confound our analysis.\n\n\nCode\n# Analyze regional distribution\nplt.figure(figsize=(10, 5))\nregional_dist = pd.crosstab(blueprinty_df['region'], blueprinty_df['iscustomer'], normalize='columns') * 100\nregional_dist.plot(kind='bar')\nplt.title('Regional Distribution by Customer Status')\nplt.xlabel('Region')\nplt.ylabel('Percentage')\nplt.legend(['Non-Customers', 'Customers'])\nplt.show()\n\nprint(\"\\nRegional Distribution (%):\")\nprint(regional_dist)\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nsns.boxplot(data=blueprinty_df[blueprinty_df['iscustomer'] == 0], y='age')\nplt.title('Age Distribution - Non-Customers')\nplt.ylabel('Age (years)')\n\nplt.subplot(1, 2, 2)\nsns.boxplot(data=blueprinty_df[blueprinty_df['iscustomer'] == 1], y='age')\nplt.title('Age Distribution - Customers')\nplt.ylabel('Age (years)')\nplt.show()\n\nprint(\"Mean Age by Customer Status:\")\nprint(blueprinty_df.groupby('iscustomer')['age'].mean())\n\n\n&lt;Figure size 960x480 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\nRegional Distribution (%):\niscustomer          0          1\nregion                          \nMidwest     18.351325   7.692308\nNortheast   26.790972  68.191268\nNorthwest   15.505397   6.029106\nSouth       15.309127   7.276507\nSouthwest   24.043180  10.810811\n\n\n\n\n\n\n\n\n\nMean Age by Customer Status:\niscustomer\n0    26.101570\n1    26.900208\nName: age, dtype: float64\n\n\nLooking at the regional distribution, we can observe notable variations in customer adoption across different regions. The northeast region shows higher proportions of Blueprinty customers than others, suggesting potential geographic clustering. This could be due to various factors such as local marketing efforts or other. The age comparison between customers and non-customers reveals that there is not much variation in age. The boxplots show that Blueprinty’s customer base does not significantly tend to differ in age composition from non-customers. The differences in regional distribution underscores the importance of controlling for this variables in our subsequent analysis. Without accounting for these factors, we might incorrectly attribute differences in patent success rates to Blueprinty’s software when they could be partially explained by this underlying characteristic.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nFor a sample of n independent observations \\(Y_1, ..., Y_n\\) from a Poisson distribution with parameter \\(\\lambda\\), the likelihood function is:\n\\(L(\\lambda|Y) = \\prod_{i=1}^n f(Y_i|\\lambda) = \\prod_{i=1}^n \\frac{e^{-\\lambda}\\lambda^{Y_i}}{Y_i!}\\)\nThis represents the probability of observing our data Y given the parameter \\(\\lambda\\). The product comes from the independence of observations.\n\n\nCode\ndef poisson_loglikelihood(lambda_, Y):\n    Y = np.array(Y)\n    n = len(Y)\n    sum_Y = np.sum(Y)\n    sum_log_factorial = np.sum(np.log(factorial(Y)))\n    return -n * lambda_ + sum_Y * np.log(lambda_) - sum_log_factorial\n\n# Calculate MLE\nY = blueprinty_df['patents'].values\nlambda_values = np.linspace(0.1, 10, 100)\n\nlog_likelihoods = [poisson_loglikelihood(lambda_, Y) for lambda_ in lambda_values]\n\nplt.figure(figsize=(10, 6))\nplt.plot(lambda_values, log_likelihoods)\nplt.xlabel('λ (lambda)')\nplt.ylabel('Log-likelihood')\nplt.title('Log-likelihood Function for Poisson Model')\nplt.grid(True)\nplt.show()\n\nsample_mean = round(np.mean(Y),2)\nprint(\"MLE for lambda: {sample_mean}\")\n\n\n\n\n\n\n\n\n\nMLE for lambda: {sample_mean}\n\n\nThe plot above shows the log-likelihood as a function of \\(\\lambda\\). The maximum occurs at the sample mean, which is the MLE for the Poisson rate parameter.\nWe can also confirm this by direct optimization:\n\n\nCode\ndef neg_poisson_loglikelihood(lambda_, Y):\n    return -poisson_loglikelihood(lambda_, Y)\n\nresult = optimize.minimize(neg_poisson_loglikelihood, x0=np.mean(Y), args=(Y,), method='BFGS')\nprint(f\"MLE of λ from optimization: {result.x[0]:.2f}\")\n\n\nMLE of λ from optimization: 3.68\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nTo account for firm characteristics, we fit a Poisson regression model where the expected number of patents depends on age, age squared, region, and customer status.\n\n\nCode\ndef neg_log_likelihood(beta, Y, X):\n    beta = np.asarray(beta, dtype=np.float64)\n    Y = np.asarray(Y, dtype=np.float64)\n    X = np.asarray(X, dtype=np.float64)\n\n    eta = X @ beta\n    eta = np.clip(eta, -20, 20)\n    lambda_ = np.exp(eta)\n\n    log_likelihood = np.sum(Y * eta - lambda_ - gammaln(Y + 1))\n    return -log_likelihood\n\n\nLet’s estimate the Poisson regression model and analyze the results:\n\n\nCode\nfrom scipy.optimize import minimize\n\nY = blueprinty_df['patents'].astype(float).values\nX = blueprinty_df[['age', 'region', 'iscustomer']].copy()\n\nX['age'] = (X['age'] - X['age'].mean()) / X['age'].std()\nX['age_squared'] = X['age'] ** 2\n\nregion_dummies = pd.get_dummies(X['region'], prefix='region', drop_first=True)\n\nX_final = pd.concat([\n    pd.Series(1.0, index=X.index, name='intercept'),\n    X[['age', 'age_squared', 'iscustomer']],\n    region_dummies], axis=1)\n\nX_np = X_final.to_numpy(dtype=np.float64)\n\ninitial_beta = np.zeros(X_np.shape[1])\nresult = minimize(\n    neg_log_likelihood,\n    x0=initial_beta,\n    args=(Y, X_np),\n    method='L-BFGS-B'\n)\n\nbeta_hat = result.x\nhessian_inv = result.hess_inv\ncov_matrix = hessian_inv.todense()\nstandard_errors = np.sqrt(np.diag(cov_matrix))\n\nsummary_df = pd.DataFrame({\n    'Coefficient': beta_hat,\n    'Std. Error': standard_errors\n}, index=X_final.columns)\n\nsummary_df = summary_df.round(4)\nprint(\"\\nPoisson Regression Results:\")\nprint(summary_df)\n\n\n\nPoisson Regression Results:\n                  Coefficient  Std. Error\nintercept              1.3447      1.1150\nage                   -0.0577      0.8972\nage_squared           -0.1558      0.3603\niscustomer             0.2076      0.6343\nregion_Northeast       0.0291      1.2075\nregion_Northwest      -0.0176      1.3685\nregion_South           0.0565      1.3112\nregion_Southwest       0.0506      0.3889\n\n\n\n\n\nNext we double check our result with the built in GLM function:\n\n\nCode\nimport statsmodels.api as sm\n\ndf = blueprinty_df.copy()\ndf['age'] = (df['age'] - df['age'].mean()) / df['age'].std()\ndf['age_squared'] = df['age'] ** 2\n\nregion_dummies = pd.get_dummies(df['region'], prefix='region', drop_first=True)\n\nmodel_df = pd.concat([\n    df[['patents', 'age', 'age_squared', 'iscustomer']],\n    region_dummies], axis=1)\n\ny = model_df['patents'].astype(float)\nX = sm.add_constant(model_df.drop(columns='patents')).astype(float)\n\npoisson_model = sm.GLM(y, X, family=sm.families.Poisson())\npoisson_results = poisson_model.fit()\n\nprint(poisson_results.summary())\n\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                patents   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Mon, 05 May 2025   Deviance:                       2143.3\nTime:                        23:56:19   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n====================================================================================\n                       coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------------\nconst                1.3447      0.038     35.059      0.000       1.270       1.420\nage                 -0.0577      0.015     -3.843      0.000      -0.087      -0.028\nage_squared         -0.1558      0.014    -11.513      0.000      -0.182      -0.129\niscustomer           0.2076      0.031      6.719      0.000       0.147       0.268\nregion_Northeast     0.0292      0.044      0.669      0.504      -0.056       0.115\nregion_Northwest    -0.0176      0.054     -0.327      0.744      -0.123       0.088\nregion_South         0.0566      0.053      1.074      0.283      -0.047       0.160\nregion_Southwest     0.0506      0.047      1.072      0.284      -0.042       0.143\n====================================================================================\n\n\nThe results from the manual calculation matches those from the built-in GLM function. This agreement provides confidence in the validity of the findings and the reliability of the modeling approach.\n\n\n\nThe Poisson regression results provide meaningful insights into the factors associated with patenting success among firms. Most notably, firms that use Blueprinty’s software are predicted to file more patents than comparable firms that do not use the software. This relationship remains positive even after controlling for other characteristics such as firm age and regional location, suggesting that Blueprinty’s tools may be effectively supporting innovation efforts.\nThe model also reveals a non-linear relationship between age and patent output: patenting tends to increase as firms age, but eventually declines, consistent with the idea that younger firms may be more dynamic and innovative, while older firms could become less agile over time.\nI made this assumption as both age and age squared are negative and statistically significant. This pattern suggests an inverted-U relationship. The patenting activity tends to rise as firms age initially, but eventually declines, indicating that older firms may become less innovative over time.\nFinally, the analysis finds no strong or consistent evidence that region plays a significant role in driving patent activity. Once differences in firm-level factors are accounted for, geographic location does not appear to be a major determinant of patenting success.\n\n\n\n\n\nCode\nX_0 = X.copy()\nX_1 = X.copy()\nX_0['iscustomer'] = 0\nX_1['iscustomer'] = 1\n\ny_pred_0 = poisson_results.predict(X_0)\ny_pred_1 = poisson_results.predict(X_1)\n\navg_effect = (y_pred_1 - y_pred_0).mean()\nprint(round(avg_effect,3))\n\n\n0.793\n\n\nTo assess the practical impact of Blueprinty’s software, we estimated the average treatment effect by comparing predicted patent counts for all firms as if they were customers versus non-customers.\nThe analysis suggests that being a customer of Blueprinty’s software has a positive effect on patent success. Using a Poisson regression model, we estimated that firms using Blueprinty’s software are expected to file approximately 0.793 more patents on average compared to similar firms that do not use the software, holding all other firm characteristics constant.\nThese results support the marketing claim that Blueprinty’s software is linked to greater patenting success. This provides strong evidence that customers of Blueprinty tend to outperform non-customers in terms of patent output, even after accounting for other important firm characteristics."
  },
  {
    "objectID": "blog/project2/hw2_questions.html#airbnb-case-study",
    "href": "blog/project2/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped 40,000 Airbnb listings from New York City. The goal of this analysis is to understand what factors influence the number of reviews a listing receives, using Poisson regression, which is well-suited for modeling count data.\nThe dataset includes variables such as price, room type, instant bookability, and review scores for cleanliness, location, and value. We begin by loading and inspecting the data to ensure it is suitable for analysis.\n\ndf = pd.read_csv(\"airbnb.csv\")\nprint(df.head())\n\n   Unnamed: 0    id  days last_scraped  host_since        room_type  \\\n0           1  2515  3130     4/2/2017    9/6/2008     Private room   \n1           2  2595  3127     4/2/2017    9/9/2008  Entire home/apt   \n2           3  3647  3050     4/2/2017  11/25/2008     Private room   \n3           4  3831  3038     4/2/2017   12/7/2008  Entire home/apt   \n4           5  4611  3012     4/2/2017    1/2/2009     Private room   \n\n   bathrooms  bedrooms  price  number_of_reviews  review_scores_cleanliness  \\\n0        1.0       1.0     59                150                        9.0   \n1        1.0       0.0    230                 20                        9.0   \n2        1.0       1.0    150                  0                        NaN   \n3        1.0       1.0     89                116                        9.0   \n4        NaN       1.0     39                 93                        9.0   \n\n   review_scores_location  review_scores_value instant_bookable  \n0                     9.0                  9.0                f  \n1                    10.0                  9.0                f  \n2                     NaN                  NaN                f  \n3                     9.0                  9.0                f  \n4                     8.0                  9.0                t  \n\n\nThe first few rows of the dataset give us a sense of the variables available and their formats. We see that the data includes both numeric and categorical variables, which will need to be processed appropriately for modeling.\n\n\nData Preparation\nBefore fitting our model, we clean the data by removing rows with missing values in key columns, converting categorical variables to numeric, and ensuring all predictors are numeric. This step is crucial for the validity of our regression analysis.\n\ndf_clean = df.dropna(subset=[\"number_of_reviews\"])\nselected_columns = [\n    \"number_of_reviews\",\n    \"price\",\n    \"room_type\",\n    \"instant_bookable\",\n    \"review_scores_cleanliness\",\n    \"review_scores_location\",\n    \"review_scores_value\"\n]\ndf_model = df_clean[selected_columns].copy()\ndf_model.dropna(inplace=True)\n\ndf_model[\"instant_bookable\"] = df_model[\"instant_bookable\"].map({\"t\": 1, \"f\": 0})\n\ndf_model = pd.get_dummies(df_model, columns=[\"room_type\"], drop_first=True)\nprint(df_model.head())\n\n   number_of_reviews  price  instant_bookable  review_scores_cleanliness  \\\n0                150     59                 0                        9.0   \n1                 20    230                 0                        9.0   \n3                116     89                 0                        9.0   \n4                 93     39                 1                        9.0   \n5                 60    212                 0                        9.0   \n\n   review_scores_location  review_scores_value  room_type_Private room  \\\n0                     9.0                  9.0                    True   \n1                    10.0                  9.0                   False   \n3                     9.0                  9.0                   False   \n4                     8.0                  9.0                    True   \n5                     9.0                  9.0                   False   \n\n   room_type_Shared room  \n0                  False  \n1                  False  \n3                  False  \n4                  False  \n5                  False  \n\n\nAfter cleaning, our modeling dataset contains only numeric columns, with categorical variables such as room type represented as dummy variables. This ensures compatibility with the Poisson regression model.\n\n\nMaximum Likelihood Estimation by Hand\nWe first fit a Poisson regression model using maximum likelihood estimation manually. This approach allows us to understand the mechanics of model fitting and provides a benchmark for comparison with built-in functions. We reused the neg_log_likelihood function from the previous case.\n\nX = df_model.drop(columns=[\"number_of_reviews\"]).copy()\nX.insert(0, \"intercept\", 1)\nX = X.values\n\ny = df_model[\"number_of_reviews\"].values\n\ninitial_beta = np.zeros(X.shape[1])\n\n# Run optimizer using your defined neg_log_likelihood(beta, Y, X)\nresult = minimize(\n    fun=neg_log_likelihood,\n    x0=initial_beta,\n    args=(y, X),\n    method='L-BFGS-B'\n)\n\n# Extract results\nestimated_beta = result.x\nconverged = result.success\nmessage = result.message\n\nprint(\"Estimated coefficients:\", estimated_beta)\nprint(\"Converged:\", converged)\nprint(\"Message:\", message)\n\nEstimated coefficients: [ 3.57242395e+00 -7.66678955e-06  3.33150991e-01  1.12891565e-01\n -8.36929510e-02 -8.88016276e-02 -2.68757331e-02 -2.66781999e-01]\nConverged: True\nMessage: CONVERGENCE: REL_REDUCTION_OF_F_&lt;=_FACTR*EPSMCH\n\n\nThe output above shows the estimated coefficients for each predictor, as well as information about the optimizer’s convergence. These coefficients represent the log effect of each variable on the expected number of reviews, holding other variables constant.\n\n\nModel Fitting with Built-in GLM\nTo validate our custom MLE results, we also fit a Poisson regression model using the built in GLM function.\n\nimport statsmodels.api as sm\n\n# Prepare data for statsmodels\nX_sm = df_model.drop(columns=[\"number_of_reviews\"]).astype(float)\nX_sm = sm.add_constant(X_sm)\ny_sm = df_model[\"number_of_reviews\"].astype(float)\n\npoisson_model = sm.GLM(y_sm, X_sm, family=sm.families.Poisson())\npoisson_results = poisson_model.fit()\n\nprint(poisson_results.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                30346\nModel:                            GLM   Df Residuals:                    30338\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -5.3507e+05\nDate:                Mon, 05 May 2025   Deviance:                   9.4783e+05\nTime:                        23:56:37   Pearson chi2:                 1.42e+06\nNo. Iterations:                     6   Pseudo R-squ. (CS):             0.5380\nCovariance Type:            nonrobust                                         \n=============================================================================================\n                                coef    std err          z      P&gt;|z|      [0.025      0.975]\n---------------------------------------------------------------------------------------------\nconst                         3.5679      0.015    233.369      0.000       3.538       3.598\nprice                     -7.422e-06   7.57e-06     -0.980      0.327   -2.23e-05    7.42e-06\ninstant_bookable              0.3324      0.003    115.542      0.000       0.327       0.338\nreview_scores_cleanliness     0.1130      0.001     76.151      0.000       0.110       0.116\nreview_scores_location       -0.0821      0.002    -51.797      0.000      -0.085      -0.079\nreview_scores_value          -0.0900      0.002    -50.354      0.000      -0.094      -0.087\nroom_type_Private room       -0.0252      0.003     -9.406      0.000      -0.031      -0.020\nroom_type_Shared room        -0.2648      0.009    -30.926      0.000      -0.282      -0.248\n=============================================================================================\n\n\nThe regression summary above provides the same values as our manual approach improving the confidence that the results are right.\n\n\nInterpretation of Results\nListings with instant booking enabled tend to receive more reviews, suggesting that ease of booking increases guest engagement. Cleanliness scores are also positively associated with review volume, highlighting the importance of hygiene.\nSurprisingly, higher scores for location and value are linked to fewer reviews. This may reflect overlapping review dimensions or unobserved guest behavior.\nEntire homes and apartments receive more reviews than private or shared rooms, likely due to greater guest preference for privacy. Price has no meaningful impact on review count.\nOverall, instant booking, cleanliness, and room type are stronger predictors of review volume than pricing or location/value ratings."
  },
  {
    "objectID": "blog/project2/hw2_questions.html#section",
    "href": "blog/project2/hw2_questions.html#section",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\ntodo: Compare regions and ages by customer status. What do you observe?\n\n# First, let's analyze regional distribution\nplt.figure(figsize=(10, 5))\nregional_dist = pd.crosstab(blueprinty_df['region'], blueprinty_df['iscustomer'], normalize='columns') * 100\nregional_dist.plot(kind='bar', alpha=0.7)\nplt.title('Regional Distribution by Customer Status')\nplt.xlabel('Region')\nplt.ylabel('Percentage')\nplt.legend(['Non-Customers', 'Customers'])\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n# Print the actual percentages\nprint(\"\\nRegional Distribution (%):\")\nprint(regional_dist)\n\n# Now, let's analyze age distribution\nplt.figure(figsize=(12, 5))\n\n# Age distribution for non-customers\nplt.subplot(1, 2, 1)\nsns.boxplot(data=blueprinty_df[blueprinty_df['iscustomer'] == 0], y='age')\nplt.title('Age Distribution - Non-Customers')\nplt.ylabel('Age (years)')\n\n# Age distribution for customers\nplt.subplot(1, 2, 2)\nsns.boxplot(data=blueprinty_df[blueprinty_df['iscustomer'] == 1], y='age')\nplt.title('Age Distribution - Customers')\nplt.ylabel('Age (years)')\n\nplt.tight_layout()\nplt.show()\n\n# Print summary statistics for age\nprint(\"\\nAge Summary Statistics:\")\nprint(blueprinty_df.groupby('iscustomer')['age'].describe())\n\n&lt;Figure size 960x480 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\nRegional Distribution (%):\niscustomer          0          1\nregion                          \nMidwest     18.351325   7.692308\nNortheast   26.790972  68.191268\nNorthwest   15.505397   6.029106\nSouth       15.309127   7.276507\nSouthwest   24.043180  10.810811\n\n\n\n\n\n\n\n\n\n\nAge Summary Statistics:\n             count       mean       std   min   25%   50%    75%   max\niscustomer                                                            \n0           1019.0  26.101570  6.945426   9.0  21.0  25.5  31.25  47.5\n1            481.0  26.900208  7.814678  10.0  20.5  26.5  32.50  49.0\n\n\nThe analysis of regional distribution and firm age reveals important systematic differences between Blueprinty customers and non-customers.\nLooking at the regional distribution, we can observe notable variations in customer adoption across different regions. Some regions show higher proportions of Blueprinty customers than others, suggesting potential geographic clustering of the software’s adoption. This could be due to various factors such as regional business networks, local marketing efforts, or industry concentrations in certain areas.\nThe age comparison between customers and non-customers is particularly revealing. The boxplots show that Blueprinty’s customer base tends to differ in age composition from non-customers. This age disparity could be an important confounding factor when analyzing patent success rates, as older firms might naturally have more experience with the patent application process and more resources to dedicate to R&D efforts.\nThese systematic differences in both regional distribution and firm age underscore the importance of controlling for these variables in our subsequent analysis. Without accounting for these factors, we might incorrectly attribute differences in patent success rates to Blueprinty’s software when they could be partially explained by these underlying characteristics.\n\nEstimation of Simple Poisson Model\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\n\nimport numpy as np\nfrom scipy.special import factorial\n\ndef poisson_loglikelihood(lambda_, Y):\n    \"\"\"\n    Calculate the log-likelihood for a Poisson model.\n    \n    Parameters:\n    lambda_ (float): Poisson rate parameter\n    Y (array-like): Observed count data\n    \n    Returns:\n    float: Log-likelihood value\n    \"\"\"\n    # Convert Y to numpy array if it isn't already\n    Y = np.array(Y)\n    \n    # Calculate the log-likelihood using the formula: -nλ + (∑Yᵢ)logλ - ∑log(Yᵢ!)\n    n = len(Y)\n    sum_Y = np.sum(Y)\n    sum_log_factorial = np.sum(np.log(factorial(Y)))\n    \n    log_likelihood = -n * lambda_ + sum_Y * np.log(lambda_) - sum_log_factorial\n    return log_likelihood\n\n# Example usage:\n# Y = [2, 3, 1, 4, 2]  # Example data\n# lambda_ = 2.5\n# print(\"Log-likelihood:\", poisson_loglikelihood(lambda_, Y))\n\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\n\nfrom scipy.special import factorial\n\n# Get the patents data from the dataframe\nY = blueprinty_df['patents'].values\n\n# Create a range of lambda values to evaluate\nlambda_values = np.linspace(0.1, 10, 100)\n\n# Calculate log-likelihood for each lambda value\nlog_likelihoods = [poisson_loglikelihood(l, Y) for l in lambda_values]\n\n# Plot the log-likelihood function\nplt.figure(figsize=(10, 6))\nplt.plot(lambda_values, log_likelihoods)\nplt.xlabel('λ (lambda)')\nplt.ylabel('Log-likelihood')\nplt.title('Log-likelihood Function for Poisson Model')\nplt.grid(True)\n\n# Add a vertical line at the sample mean (which is the MLE)\nsample_mean = np.mean(Y)\nplt.axvline(x=sample_mean, color='r', linestyle='--', \n            label=f'MLE (λ = {sample_mean:.2f})')\nplt.legend()\n\nplt.show()\n\n# Print the MLE value\nprint(f\"Maximum Likelihood Estimate (MLE) of λ: {sample_mean:.2f}\")\n\n\n\n\n\n\n\n\nMaximum Likelihood Estimate (MLE) of λ: 3.68\n\n\ntodo: If you’re feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which “feels right” because the mean of a Poisson distribution is lambda.\n\n# Mathematical derivation of the MLE for Poisson distribution:\n\n# The log-likelihood function is:\n# ℓ(λ) = -nλ + (∑Yᵢ)logλ - ∑log(Yᵢ!)\n\n# Taking the first derivative with respect to λ:\n# dℓ/dλ = -n + (∑Yᵢ)/λ\n\n# Setting the derivative equal to zero to find the maximum:\n# -n + (∑Yᵢ)/λ = 0\n# (∑Yᵢ)/λ = n\n# λ = (∑Yᵢ)/n = Ȳ\n\n# Therefore, the MLE of λ is the sample mean Ȳ\n\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\n\n\nEstimation of Poisson Regression Model\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\npoisson_regression_likelihood &lt;- function(beta, Y, X){\n   ...\n}\ntodo: Use your function along with R’s optim() or Python’s sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1’s to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\ntodo: Check your results using R’s glm() function or Python sm.GLM() function.\ntodo: Interpret the results.\ntodo: What do you conclude about the effect of Blueprinty’s software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "blog/project2/hw2_questions.html#executive-summary",
    "href": "blog/project2/hw2_questions.html#executive-summary",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "This report presents two case studies demonstrating the application of Poisson regression in business analytics. The first case study examines the relationship between Blueprinty’s software usage and patent success rates, while the second analyzes factors influencing AirBnB listing reviews. Both analyses utilize Poisson regression to model count data, accounting for various covariates and potential confounding factors."
  },
  {
    "objectID": "blog/project2/hw2_questions.html#conclusion",
    "href": "blog/project2/hw2_questions.html#conclusion",
    "title": "Poisson Regression Examples",
    "section": "Conclusion",
    "text": "Conclusion\nThis analysis demonstrates the application of Poisson regression in two distinct business contexts: patent analysis for Blueprinty and review analysis for AirBnB. In both cases, we successfully modeled count data using Poisson regression.\nFor Blueprinty, our analysis revealed that firms using their software tend to have higher patent success rates, even after controlling for firm age and regional differences. The Poisson regression model provided valuable insights into the relationship between software usage and patent outcomes, supporting the marketing team’s claims while accounting for important confounding variables.\nIn the AirBnB case study, we identified key factors influencing the number of reviews, with instant bookability and room type showing particularly strong effects. The analysis provides actionable insights for hosts looking to increase their listing visibility and engagement."
  },
  {
    "objectID": "blog/project3/hw3_questions.html",
    "href": "blog/project3/hw3_questions.html",
    "title": "Multinomial Logit Model",
    "section": "",
    "text": "This assignment expores two methods for estimating the MNL model: (1) via Maximum Likelihood, and (2) via a Bayesian approach using a Metropolis-Hastings MCMC algorithm."
  },
  {
    "objectID": "blog/project3/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "href": "blog/project3/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "title": "Multinomial Logit Model",
    "section": "1. Likelihood for the Multi-nomial Logit (MNL) Model",
    "text": "1. Likelihood for the Multi-nomial Logit (MNL) Model\nSuppose we have \\(i=1,\\ldots,n\\) consumers who each select exactly one product \\(j\\) from a set of \\(J\\) products. The outcome variable is the identity of the product chosen \\(y_i \\in \\{1, \\ldots, J\\}\\) or equivalently a vector of \\(J-1\\) zeros and \\(1\\) one, where the \\(1\\) indicates the selected product. For example, if the third product was chosen out of 3 products, then either \\(y=3\\) or \\(y=(0,0,1)\\) depending on how we want to represent it. Suppose also that we have a vector of data on each product \\(x_j\\) (eg, brand, price, etc.).\nWe model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:\n\\[ U_{ij} = x_j'\\beta + \\epsilon_{ij} \\]\nwhere \\(\\epsilon_{ij}\\) is an i.i.d. extreme value error term.\nThe choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer \\(i\\) chooses product \\(j\\):\n\\[ \\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nFor example, if there are 3 products, the probability that consumer \\(i\\) chooses product 3 is:\n\\[ \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{e^{x_1'\\beta} + e^{x_2'\\beta} + e^{x_3'\\beta}} \\]\nA clever way to write the individual likelihood function for consumer \\(i\\) is the product of the \\(J\\) probabilities, each raised to the power of an indicator variable (\\(\\delta_{ij}\\)) that indicates the chosen product:\n\\[ L_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} = \\mathbb{P}_i(1)^{\\delta_{i1}} \\times \\ldots \\times \\mathbb{P}_i(J)^{\\delta_{iJ}}\\]\nNotice that if the consumer selected product \\(j=3\\), then \\(\\delta_{i3}=1\\) while \\(\\delta_{i1}=\\delta_{i2}=0\\) and the likelihood is:\n\\[ L_i(\\beta) = \\mathbb{P}_i(1)^0 \\times \\mathbb{P}_i(2)^0 \\times \\mathbb{P}_i(3)^1 = \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{\\sum_{k=1}^3e^{x_k'\\beta}} \\]\nThe joint likelihood (across all consumers) is the product of the \\(n\\) individual likelihoods:\n\\[ L_n(\\beta) = \\prod_{i=1}^n L_i(\\beta) = \\prod_{i=1}^n \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} \\]\nAnd the joint log-likelihood function is:\n\\[ \\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j)) \\]"
  },
  {
    "objectID": "blog/project3/hw3_questions.html#simulate-conjoint-data",
    "href": "blog/project3/hw3_questions.html#simulate-conjoint-data",
    "title": "Multinomial Logit Model",
    "section": "2. Simulate Conjoint Data",
    "text": "2. Simulate Conjoint Data\nWe will simulate data from a conjoint experiment about video content streaming services. We elect to simulate 100 respondents, each completing 10 choice tasks, where they choose from three alternatives per task. For simplicity, there is not a “no choice” option; each simulated respondent must select one of the 3 alternatives.\nEach alternative is a hypothetical streaming offer consistent of three attributes: (1) brand is either Netflix, Amazon Prime, or Hulu; (2) ads can either be part of the experience, or it can be ad-free, and (3) price per month ranges from $4 to $32 in increments of $4.\nThe part-worths (ie, preference weights or beta parameters) for the attribute levels will be 1.0 for Netflix, 0.5 for Amazon Prime (with 0 for Hulu as the reference brand); -0.8 for included adverstisements (0 for ad-free); and -0.1*price so that utility to consumer \\(i\\) for hypothethical streaming service \\(j\\) is\n\\[\nu_{ij} = (1 \\times Netflix_j) + (0.5 \\times Prime_j) + (-0.8*Ads_j) - 0.1\\times Price_j + \\varepsilon_{ij}\n\\]\nwhere the variables are binary indicators and \\(\\varepsilon\\) is Type 1 Extreme Value (ie, Gumble) distributed.\nThe following code provides the simulation of the conjoint data.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nimport numpy as np\nimport pandas as pd\n\n# set seed for reproducibility\nnp.random.seed(123)\n\n# define attributes\nbrand = [\"N\", \"P\", \"H\"]  # Netflix, Prime, Hulu\nad = [\"Yes\", \"No\"]\nprice = list(range(8, 33, 4))\n\n# generate all possible profiles\nprofiles = pd.DataFrame([\n    (b, a, p) for b in brand for a in ad for p in price\n], columns=[\"brand\", \"ad\", \"price\"])\nm = len(profiles)\n\n# assign part-worth utilities (true parameters)\nb_util = {\"N\": 1.0, \"P\": 0.5, \"H\": 0}\na_util = {\"Yes\": -0.8, \"No\": 0.0}\ndef p_util(p): return -0.1 * p\n\n# number of respondents, choice tasks, and alternatives per task\nn_peeps = 100\nn_tasks = 10\nn_alts = 3\n\n# function to simulate one respondent's data\ndef sim_one(id):\n    datlist = []\n    for t in range(1, n_tasks + 1):\n        dat = profiles.sample(n=n_alts).copy()\n        dat.insert(0, \"task\", t)\n        dat.insert(0, \"resp\", id)\n        dat[\"v\"] = (\n            dat[\"brand\"].map(b_util) +\n            dat[\"ad\"].map(a_util) +\n            dat[\"price\"].apply(p_util)\n        ).round(10)\n        dat[\"e\"] = -np.log(-np.log(np.random.uniform(size=n_alts)))\n        dat[\"u\"] = dat[\"v\"] + dat[\"e\"]\n        dat[\"choice\"] = (dat[\"u\"] == dat[\"u\"].max()).astype(int)\n        datlist.append(dat)\n    return pd.concat(datlist, ignore_index=True)\n\n# simulate data for all respondents\nconjoint_data = pd.concat([sim_one(i) for i in range(1, n_peeps + 1)], ignore_index=True)\n\n# remove values unobservable to the researcher\nconjoint_data = conjoint_data[[\"resp\", \"task\", \"brand\", \"ad\", \"price\", \"choice\"]]\n\n# clean up\nfor name in dir():\n    if name != \"conjoint_data\":\n        del globals()[name]\n\nprint(conjoint_data.head())\n\n   resp  task brand  ad  price  choice\n0     1     1     P  No     32       0\n1     1     1     N  No     28       0\n2     1     1     N  No     24       1\n3     1     2     H  No     28       0\n4     1     2     H  No      8       1"
  },
  {
    "objectID": "blog/project3/hw3_questions.html#preparing-the-data-for-estimation",
    "href": "blog/project3/hw3_questions.html#preparing-the-data-for-estimation",
    "title": "Multinomial Logit Model",
    "section": "3. Preparing the Data for Estimation",
    "text": "3. Preparing the Data for Estimation\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)). The fact that each task for each respondent has the same number of alternatives (3) helps. In addition, we need to convert the categorical variables for brand and ads into binary variables.\ntodo: reshape and prep the data\n\nconjoint_data['brand_netflix'] = (conjoint_data['brand'] == 'N').astype(int)\nconjoint_data['brand_prime'] = (conjoint_data['brand'] == 'P').astype(int)\nconjoint_data['ads_yes'] = (conjoint_data['ad'] == 'Yes').astype(int)\n\nX = conjoint_data[['brand_netflix', 'brand_prime', 'ads_yes', 'price']].values\ny = conjoint_data['choice'].values\n\nrespondent = conjoint_data['resp'].values\ntask = conjoint_data['task'].values\n\nprint(conjoint_data.head())\n\n   resp  task brand  ad  price  choice  brand_netflix  brand_prime  ads_yes\n0     1     1     P  No     32       0              0            1        0\n1     1     1     N  No     28       0              1            0        0\n2     1     1     N  No     24       1              1            0        0\n3     1     2     H  No     28       0              0            0        0\n4     1     2     H  No      8       1              0            0        0"
  },
  {
    "objectID": "blog/project3/hw3_questions.html#estimation-via-maximum-likelihood",
    "href": "blog/project3/hw3_questions.html#estimation-via-maximum-likelihood",
    "title": "Multinomial Logit Model",
    "section": "4. Estimation via Maximum Likelihood",
    "text": "4. Estimation via Maximum Likelihood\ntodo: Code up the log-likelihood function.\n\nimport numpy as np\n\ndef mnl_log_likelihood(beta, X, y, task_ids):\n    v = X @ beta  # (n_samples,)\n    \n    unique_tasks = np.unique(task_ids)\n    log_likelihood = 0.0\n    for t in unique_tasks:\n        idx = (task_ids == t)\n        v_t = v[idx]\n        y_t = y[idx]\n        # Compute log-sum-exp for denominator\n        denom = np.log(np.sum(np.exp(v_t)))\n        # For the chosen alternative (y==1), add v - denom\n        log_likelihood += np.sum(y_t * (v_t - denom))\n    # Return negative log-likelihood for minimization\n    return -log_likelihood\n\n# Prepare task_ids (each unique resp-task pair is a choice set)\ntask_ids = conjoint_data['resp'].astype(str) + \"_\" + conjoint_data['task'].astype(str)\ntask_ids = task_ids.values\n\n# Example: test with initial beta\nbeta_init = np.zeros(4)\nnll = mnl_log_likelihood(beta_init, X, y, task_ids)\nprint(\"Negative log-likelihood at beta=0:\", nll)\n\nNegative log-likelihood at beta=0: 1098.6122886681378\n\n\ntodo: Use optim() in R or scipy.optimize() in Python to find the MLEs for the 4 parameters (\\(\\beta_\\text{netflix}\\), \\(\\beta_\\text{prime}\\), \\(\\beta_\\text{ads}\\), \\(\\beta_\\text{price}\\)), as well as their standard errors (from the Hessian). For each parameter construct a 95% confidence interval."
  },
  {
    "objectID": "blog/project3/hw3_questions.html#estimation-via-bayesian-methods",
    "href": "blog/project3/hw3_questions.html#estimation-via-bayesian-methods",
    "title": "Multinomial Logit Model",
    "section": "5. Estimation via Bayesian Methods",
    "text": "5. Estimation via Bayesian Methods\ntodo: code up a metropolis-hasting MCMC sampler of the posterior distribution. Take 11,000 steps and throw away the first 1,000, retaining the subsequent 10,000.\nhint: Use N(0,5) priors for the betas on the binary variables, and a N(0,1) prior for the price beta.\n_hint: instead of calculating post=lik*prior, you can work in the log-space and calculate log-post = log-lik + log-prior (this should enable you to re-use your log-likelihood function from the MLE section just above)_\nhint: King Markov (in the video) use a candidate distribution of a coin flip to decide whether to move left or right among his islands. Unlike King Markov, we have 4 dimensions (because we have 4 betas) and our dimensions are continuous. So, use a multivariate normal distribution to pospose the next location for the algorithm to move to. I recommend a MNV(mu, Sigma) where mu=c(0,0,0,0) and sigma has diagonal values c(0.05, 0.05, 0.05, 0.005) and zeros on the off-diagonal. Since this MVN has no covariances, you can sample each dimension independently (so 4 univariate normals instead of 1 multivariate normal), where the first 3 univariate normals are N(0,0.05) and the last one if N(0,0.005).\ntodo: for at least one of the 4 parameters, show the trace plot of the algorithm, as well as the histogram of the posterior distribution.\ntodo: report the 4 posterior means, standard deviations, and 95% credible intervals and compare them to your results from the Maximum Likelihood approach."
  },
  {
    "objectID": "blog/project3/hw3_questions.html#discussion",
    "href": "blog/project3/hw3_questions.html#discussion",
    "title": "Multinomial Logit Model",
    "section": "6. Discussion",
    "text": "6. Discussion\ntodo: Suppose you did not simulate the data. What do you observe about the parameter estimates? What does \\(\\beta_\\text{Netflix} &gt; \\beta_\\text{Prime}\\) mean? Does it make sense that \\(\\beta_\\text{price}\\) is negative?\ntodo: At a high level, discuss what change you would need to make in order to simulate data from — and estimate the parameters of — a multi-level (aka random-parameter or hierarchical) model. This is the model we use to analyze “real world” conjoint data."
  }
]